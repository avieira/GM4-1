\part{Systèmes linéaires invariants}
Soit $S$ donné par :
\[\left\{ \begin{array}{c c c}
\dot{x}(t)&=&Ax(t)+Bu(t)\\
y(t)&=&Cx(t)\\
x(t_0) & &\text{ donné}
\end{array}\right.\]

A,B,C matrices à coefficients constants.\\
\underline{Notation :} S donné par (A,B,C).

\section{Critère de Kalman - Controlabilité}
Soit $S$ d'équation d'état $\dot{x}(t)=Ax(t)+Bu(t)$, $x(t)\in\mathbb{R}^n$, $u(t)\in\mathbb{R}^n$.\\
On sait résoudre explicitement cette équation, mais les calculs sont longs.

\Lem{}{Pour toute matrice $(n,n)$ à coefficients constants, il existe des fonctions salaires non nulles $\gamma_i(t)$ vérifiant :
\[e^{At}=\gamma_0(t)I+\gamma_1(t)A+...+\gamma_{n-1}(t)A^{n-1}\]}

\begin{dem}
On sait que toute matrice annule son polynôme caractéristique (Théorème de Cayley-Hamilton).\\
\[\det(\lambda I-A)=\lambda^n+a_{n-1}\lambda^{n-1}+....+a_1\lambda+a_0\]
\[\Rightarrow A^n+a_{n-1}A^{n-1}+...+a_1A+a_0I=0\]
$\Rightarrow\ A^n$ peut s'exprimer en fonction de $I,A,...,A^{n-1}$.

\bigskip
Or, $A^{n+1}=A^n$, donc $\forall j\geq n$, $A^j$ s'exprime en fonction de $I,A,...,A^{n-1}$.

D'où:
\[e^{At}=\sum_{k=0}^{+\infty} \frac{t^k}{k!} A^k = \gamma_0(t)I+...+\gamma_{n-1}(t)A^{n-1}\]
\end{dem}

\Theo{de Kalman}{$S:\dot{x}(t)=Ax(t)+Bu(t)$ est complètement contrôlable sur $\mathbb{R}^n$ si et seulement si
\[\text{rang}(B\ AB\ A^2B\ \cdots \ A^{n-1}B)=n\]}

\begin{dem}
On cherche à partir d'un état initial $x(t_0)$ à atteindre un état final $z_2$.
\[z_2=x_u(t,x(t_0))=e^{A(t-t_0)}x(t_0)+e^{At}\int_{t_0}^t e^{-As}Bu(s) ds\]
\begin{eqnarray*}
e^{-At}\left(z_2-e^{A(t-t_0)}x(t_0)\right)&=&\int_{t_0}^t e^{-As}Bu(s) ds\\
					&=&\int_{t_0}^t \left(\gamma_0(-s)I+...+\gamma_{n-1}(-s)A^{n-1}\right)Bu(s)ds \\
					&=&\underbrace{\begin{pmatrix}B & AB & ... & A^{n-1}B\end{pmatrix}}_{\phi} \underbrace{\begin{pmatrix}\int_{t_0}^t \gamma_0(-s)u(s) ds \\ \vdots \\ \int_{t_0}^t \gamma_{n-1}(-s)u(s)ds  \end{pmatrix}}_{v(t)}
\end{eqnarray*}
$\forall \tilde{x}(t)$, si rang$\phi=n$, alors $\exists ! v(t) | e^{-At}\tilde{x}(t)=\phi v(t)$. La réciproque est vraie.
\end{dem}

\Exemp{}{$A=\begin{pmatrix}1 & 1 \\ 1 & 2 \end{pmatrix}$ et $B=\begin{pmatrix} 1 \\ 1 \end{pmatrix}$.
\[\text{rg}(B\ AB)=\text{rg}\begin{pmatrix} 1 & 1 \\ 1 & 3 \end{pmatrix} = 2\]
Donc complètement contrôlable.}

\Prop{}{Il y a équivalence entre les trois propositions :
\begin{enumerate}
	\item S complètement contrôlable sur $\mathbb{R}^n$
	\item $\text{rang}(B\ AB\ A^2B\ \cdots \ A^{n-1}B)=n$
	\item S est contrôlable depuis l'origine.
\end{enumerate}}

\section{Critère de Kalman - Observabilité}
\subsection{Théorème}
\Def{Complètement observable}{S est dut complètement observable si S est observable $\forall t_0>0$.}

\Theo{de Kalman}{\[S:\left\{\begin{array}{c c c}
\dot{x}(t)&=&Ax(t)+Bu(t)\\
y(t)&=&Cx(t)
\end{array}\right.\]
\[x(t)\in\mathbb{R}^n, u(t)\in\mathbb{R}^m, y(t)\in\mathbb{R}^p\]
S est complètement observable si et seulement si rang$(C\ CA\ ...\ CA^{n-1})=n$}

\Exemp{}{\[S:\left\{\begin{array}{c c c}
\dot{x}(t)&=&ax(t)+bu(t)\\
y(t)&=&cx(t)
\end{array}\right.\]
$a,b,c,x(t),y(t),u(t)\in\mathbb{R}$.\\
S complètement contrôlable sur $\mathbb{R}$ $\Leftrightarrow$ rang$(b)=1$ $\Leftrightarrow$ $b\neq 0$\\
S complètement observable $\Leftrightarrow$ rang$(c)=1$ $\Leftrightarrow$ $c\neq 0$\\}

\subsection{Observateur de Luenberger}
Soit $S$ un système linéaire invariant (A,B,C), $x(t_0)$ donné.

\bigskip
$\theta$ observateur donné par :
\[\left\{\begin{array}{c c c}
\dot{\hat{x}}(t)&=&A\hat{x}(t)+Bu(t)+L(y(t)-C\hat{x}(t))\\
\hat{y}(t)&=&C\hat{x}(t)
\end{array}\right.\]

\[\left\{\begin{array}{c c c}
\dot{\hat{x}}(t)&=&(A-LC)\hat{x}(t)+\left(B\ L\right) \begin{pmatrix} u(t) \\ y(t) \end{pmatrix}\\
\hat{y}(t)&=&C\hat{x}(t)
\end{array}\right.\]

\[\left\{\begin{array}{c c c}
\dot{\hat{x}}(t)&=&\hat{A}\hat{x}(t)+\hat{B}v(t)\\
\hat{y}(t)&=&C\hat{x}(t)
\end{array}\right.\]

On voudrait $e(t)=x(t)-\hat{x}(t)$ s'approche le plus possible de 0.
\begin{eqnarray*}
\dot{e}(t)&=&\dot{x}(t)-\dot{\hat{x}}(t)\\
	&=&A(x(t)-\hat{x}(t))-Ly(t)+LC\hat{x}(t) \\
	&=&Ae(t)-LCx(t)+LC\hat{x}(t)\\
	&=&\underbrace{(A-LC)}_M e(t)
\end{eqnarray*}

On sait que $\dot{e}(t)=Me(t)$ est asymptotiquement stable en $O$ si et seulement si $M$ est diagonalisable et \[\max_{\lambda\in Sp(M)} \Re(\lambda)<0\]

\Prop{}{Si S est complètement obersable, alors L existe.}

\subsection{Critère des valeurs propres}
On s'intéresse au système suivant, défini par bloc :
\[\left\{ \begin{array}{c c c}
\dot{x}(t)&=&\begin{pmatrix} A_1 & \times & \times & \times \\ 0 & A_2 & \times & \times \\ 0 & 0 & A_3 & \times \\ 0 & 0 & 0 & A_4 \end{pmatrix} x(t) + \begin{pmatrix} B_1 \\ B_2 \\ 0 \\ 0 \end{pmatrix} u(t) \\
y(t)&=&\begin{pmatrix} 0 & C_2 & C_3 & 0 \end{pmatrix} x(t)
\end{array}\right.\]

\begin{minipage}{0.4\linewidth}
\begin{tikzpicture}
		\draw [->] (0,5) -- (0.5,5) -- (0.5,6) -- (1.5,6);
		\draw (0,5) node[left] {$U(s)$} ;
		\draw (2,6) circle (0.5);
		\draw (2,6) node{$S_1$};
		\draw [->] (0.5,5) -- (0.5,4) -- (1.5,4);
		\draw (2,4) circle (0.5);
		\draw (2,4) node{$S_2$};
		\draw [->] (2.5,4) -- (3.5,4) -- (3.5,3) -- (4,3);
		\draw (4,3) node[right]{$Y(s)$};
		\draw (2,2) circle (0.5);
		\draw (2,2) node{$S_3$};
		\draw (2.5,2) -- (3.5,2) -- (3.5,3);
		\draw (2,0) circle (0.5);
		\draw (2,0) node{$S_4$};
\end{tikzpicture}
\end{minipage}\hspace{0.1\linewidth}
\begin{minipage}{0.4\linewidth}
$S_1$ est controlable non observable\\
$S_2$ est controlable observable\\
$S_1$ est non controlable observable\\
$S_1$ est non controlable non observable\\
\end{minipage}

\Prop{}{La matrice de transfert de S est égale à la marice de transfert de $S_2$, controlable et observable.}

\underline{Remarque :} Dans $G(s)$, on peut perdre de l'information sur les observations qui ne sont pas contrôlable ou observable

\section{Stabilisation}
\Rap{}{$\dot{x}=Ax$ stable en 0 : $\max_{\lambda \in Sp(A)} \Re(\lambda)\leq 0$\\
Asymtotiquement stable : $\max_{\lambda \in Sp(A)} \Re(\lambda)< 0$\\}

\Lem{de Lyapounov}{$\dot{x}=Ax$ est asymptotiquement stable en 0 si et seulement si l'équation $AX-{}^tXA=P$, avec $P$ symétrique définie positive, admet une solution symétrique définie négative.}

\underline{Exercice :} Montrez que $X=\int_0^{+\infty} e^{As}Pe^{{}^tAs} ds$ résoud l'équation

\bigskip
On aimerait trouver $u(t)=Kx(t)$, fonnction linéaire de $x(t)$ avec $K$ matrice à coefficients constants tel que $S$ soit asymptotiquement stable en 0.

\begin{eqnarray*}
\dot{x}&=&(Ax(t)+BKx(t)\\
	&=& (A+BK)x(t)\\
	&=& Mx(t)
\end{eqnarray*}

Il suffit donc de trouver $K$ tel que : \[\max_{\lambda\in Sp(A+BK)} \Re(\lambda)<0\]

\Prop{}{Si $S$ est complètement controlable sur $\mathbb{R}^n$, alors $\exists K=(k_1,...,k_n)$ tek que $u=Kx$ stabilise asymptotiquement $S$ à l'origine.}

\section{Linéarisation d'un système non linéaire}
\[S:\left\{ \begin{array}{c c c} \dot{x}(t)&=&f(x(t),u(t)) \\ y(t)&=&h(x(t)) \end{array} \right.\]

\Def{}{$(x_0,u_0)\in\mathbb{R}^n\times\mathbb{R}^m$ est un point d'équilibre pour S si $f(x_0,u_0)=0$}

On note \[\varepsilon=\{(x_0,u_0)\in\mathbb{R}^n\times\mathbb{R}^m; f(x_0,u_0)=0\}\]

On fait un DL d'ordre 1 (en supposant $f$ et $h$ de classe $\mathcal{C}^1$) :
\Def{}{\[\left\{\begin{array}{c c c}
\dot{z}(t)&=&Az(t)+Bu(t)\\
\tilde{y}(t)&=&Cz(t)
\end{array}\right.\]
est le linéarisé de $Z$ en $(x_0,u_0)\in\varepsilon$.
\[\frac{\partial f}{\partial x} (x_0,u_0),\ B=\frac{\partial f}{\partial u}(x_0,u_0),\ C=\frac{\partial h}{\partial x} (x_0)\]
\[z(t)=x(t)-x_0,\ v(t)=u(t)-u_0,\ \tilde{y}=y(t)-h(x_0)\]}

\Def{}{S non linéaire, est dit pseudo-linéaire si les matrices A, B et C ne dépendent pas de $(x_0,u_0)\in\varepsilon$.}

\Def{}{$(x_0,u_0)$ point d'équilibre de $S$ est dit critique si la matrice $A=\frac{\partial f}{\partial x} (x_0,u_0)$ admet au moins une valeur propre imaginaire pure}

\Theo{de Hartman}{La stabilité du linéairisé est conservé pour le système complet dans le voisinage du point considéré}
